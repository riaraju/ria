{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54358ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries and creating a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01283206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace13051",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Artificial intelligence (AI) is the simulation of human intelligence in machines programmed to think and mimic cognitive functions.\",\n",
    "    \"AI can be categorized into narrow AI, which is designed for a particular task, and general AI, which aims to perform any intellectual task that a human can.\",\n",
    "    \"The field of AI involves various subfields like machine learning, natural language processing, computer vision, and robotics.\",\n",
    "    \"Deep learning, a subset of machine learning, involves neural networks with many layers (deep neural networks) and has been successful in various AI applications.\",\n",
    "    \"Ethical considerations and responsible AI development are becoming increasingly important as AI technologies advance.\",\n",
    "    \"AI is used in diverse applications, from virtual assistants and recommendation systems to autonomous vehicles and medical diagnosis.\",\n",
    "    \"The Turing test, proposed by Alan Turing, is a measure of a machine's ability to exhibit intelligent behavior indistinguishable from that of a human.\",\n",
    "    \"AI has the potential to revolutionize industries, but it also raises concerns about job displacement and the ethical implications of autonomous decision-making.\",\n",
    "    \"Researchers and policymakers are working on guidelines and regulations to ensure the ethical and responsible use of AI technologies.\",\n",
    "    \"As AI continues to evolve, interdisciplinary collaboration and public awareness play crucial roles in shaping its impact on society.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ed3ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N gram model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "701ff0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc373222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(corpus):\n",
    "    return [['<s>'] + sentence.lower().split() + ['</s>'] for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8067142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_n_gram_model(corpus, n=2):\n",
    "    model = defaultdict(Counter)\n",
    "    for sentence in corpus:\n",
    "        for i in range(len(sentence)-n+1):\n",
    "            n_gram_sequence = tuple(sentence[i:i+n-1])\n",
    "            next_word = sentence[i+n-1]\n",
    "            model[n_gram_sequence][next_word] += 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "592427a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the N-Gram probabilities\n",
    "\n",
    "def calculate_n_gram_probabilities(model):\n",
    "    probabilities = {}\n",
    "    for n_gram_sequence, words in model.items():\n",
    "        total_count = sum(words.values())\n",
    "        probabilities[n_gram_sequence] = {word: count/total_count for word, count in words.items()}\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f39ce6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the  perplexity for N-Gram model\n",
    "def calculate_perplexity(model, corpus, n=2):\n",
    "    N = sum(len(sentence) for sentence in corpus)\n",
    "    logprob = 0\n",
    "    for sentence in corpus:\n",
    "        for i in range(n-1, len(sentence)):\n",
    "            n_gram_sequence = tuple(sentence[i-n+1:i])\n",
    "            word = sentence[i]\n",
    "            probability = model.get(n_gram_sequence, {}).get(word, 1e-12)  # Smoothing for zero probabilities\n",
    "            logprob += np.log2(probability)\n",
    "    perplexity = 2 ** (-logprob / N)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "243c1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_corpus = preprocess_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5efb294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'ai',\n",
       " 'can',\n",
       " 'be',\n",
       " 'categorized',\n",
       " 'into',\n",
       " 'narrow',\n",
       " 'ai,',\n",
       " 'which',\n",
       " 'is',\n",
       " 'designed',\n",
       " 'for',\n",
       " 'a',\n",
       " 'particular',\n",
       " 'task,',\n",
       " 'and',\n",
       " 'general',\n",
       " 'ai,',\n",
       " 'which',\n",
       " 'aims',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'any',\n",
       " 'intellectual',\n",
       " 'task',\n",
       " 'that',\n",
       " 'a',\n",
       " 'human',\n",
       " 'can.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9907e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {('<s>',): Counter({'ai': 3,\n",
       "                      'the': 2,\n",
       "                      'artificial': 1,\n",
       "                      'deep': 1,\n",
       "                      'ethical': 1,\n",
       "                      'researchers': 1,\n",
       "                      'as': 1}),\n",
       "             ('artificial',): Counter({'intelligence': 1}),\n",
       "             ('intelligence',): Counter({'(ai)': 1, 'in': 1}),\n",
       "             ('(ai)',): Counter({'is': 1}),\n",
       "             ('is',): Counter({'the': 1, 'designed': 1, 'used': 1, 'a': 1}),\n",
       "             ('the',): Counter({'ethical': 2,\n",
       "                      'simulation': 1,\n",
       "                      'field': 1,\n",
       "                      'turing': 1,\n",
       "                      'potential': 1}),\n",
       "             ('simulation',): Counter({'of': 1}),\n",
       "             ('of',): Counter({'ai': 2,\n",
       "                      'a': 2,\n",
       "                      'human': 1,\n",
       "                      'machine': 1,\n",
       "                      'autonomous': 1}),\n",
       "             ('human',): Counter({'intelligence': 1, 'can.': 1}),\n",
       "             ('in',): Counter({'machines': 1,\n",
       "                      'various': 1,\n",
       "                      'diverse': 1,\n",
       "                      'shaping': 1}),\n",
       "             ('machines',): Counter({'programmed': 1}),\n",
       "             ('programmed',): Counter({'to': 1}),\n",
       "             ('to',): Counter({'think': 1,\n",
       "                      'perform': 1,\n",
       "                      'autonomous': 1,\n",
       "                      'exhibit': 1,\n",
       "                      'revolutionize': 1,\n",
       "                      'ensure': 1,\n",
       "                      'evolve,': 1}),\n",
       "             ('think',): Counter({'and': 1}),\n",
       "             ('and',): Counter({'responsible': 2,\n",
       "                      'mimic': 1,\n",
       "                      'general': 1,\n",
       "                      'robotics.': 1,\n",
       "                      'has': 1,\n",
       "                      'recommendation': 1,\n",
       "                      'medical': 1,\n",
       "                      'the': 1,\n",
       "                      'policymakers': 1,\n",
       "                      'regulations': 1,\n",
       "                      'public': 1}),\n",
       "             ('mimic',): Counter({'cognitive': 1}),\n",
       "             ('cognitive',): Counter({'functions.': 1}),\n",
       "             ('functions.',): Counter({'</s>': 1}),\n",
       "             ('ai',): Counter({'can': 1,\n",
       "                      'involves': 1,\n",
       "                      'applications.': 1,\n",
       "                      'development': 1,\n",
       "                      'technologies': 1,\n",
       "                      'is': 1,\n",
       "                      'has': 1,\n",
       "                      'technologies.': 1,\n",
       "                      'continues': 1}),\n",
       "             ('can',): Counter({'be': 1}),\n",
       "             ('be',): Counter({'categorized': 1}),\n",
       "             ('categorized',): Counter({'into': 1}),\n",
       "             ('into',): Counter({'narrow': 1}),\n",
       "             ('narrow',): Counter({'ai,': 1}),\n",
       "             ('ai,',): Counter({'which': 2}),\n",
       "             ('which',): Counter({'is': 1, 'aims': 1}),\n",
       "             ('designed',): Counter({'for': 1}),\n",
       "             ('for',): Counter({'a': 1}),\n",
       "             ('a',): Counter({'particular': 1,\n",
       "                      'human': 1,\n",
       "                      'subset': 1,\n",
       "                      'measure': 1,\n",
       "                      \"machine's\": 1,\n",
       "                      'human.': 1}),\n",
       "             ('particular',): Counter({'task,': 1}),\n",
       "             ('task,',): Counter({'and': 1}),\n",
       "             ('general',): Counter({'ai,': 1}),\n",
       "             ('aims',): Counter({'to': 1}),\n",
       "             ('perform',): Counter({'any': 1}),\n",
       "             ('any',): Counter({'intellectual': 1}),\n",
       "             ('intellectual',): Counter({'task': 1}),\n",
       "             ('task',): Counter({'that': 1}),\n",
       "             ('that',): Counter({'a': 1, 'of': 1}),\n",
       "             ('can.',): Counter({'</s>': 1}),\n",
       "             ('field',): Counter({'of': 1}),\n",
       "             ('involves',): Counter({'various': 1, 'neural': 1}),\n",
       "             ('various',): Counter({'subfields': 1, 'ai': 1}),\n",
       "             ('subfields',): Counter({'like': 1}),\n",
       "             ('like',): Counter({'machine': 1}),\n",
       "             ('machine',): Counter({'learning,': 2}),\n",
       "             ('learning,',): Counter({'natural': 1, 'a': 1, 'involves': 1}),\n",
       "             ('natural',): Counter({'language': 1}),\n",
       "             ('language',): Counter({'processing,': 1}),\n",
       "             ('processing,',): Counter({'computer': 1}),\n",
       "             ('computer',): Counter({'vision,': 1}),\n",
       "             ('vision,',): Counter({'and': 1}),\n",
       "             ('robotics.',): Counter({'</s>': 1}),\n",
       "             ('deep',): Counter({'learning,': 1}),\n",
       "             ('subset',): Counter({'of': 1}),\n",
       "             ('neural',): Counter({'networks': 1, 'networks)': 1}),\n",
       "             ('networks',): Counter({'with': 1}),\n",
       "             ('with',): Counter({'many': 1}),\n",
       "             ('many',): Counter({'layers': 1}),\n",
       "             ('layers',): Counter({'(deep': 1}),\n",
       "             ('(deep',): Counter({'neural': 1}),\n",
       "             ('networks)',): Counter({'and': 1}),\n",
       "             ('has',): Counter({'been': 1, 'the': 1}),\n",
       "             ('been',): Counter({'successful': 1}),\n",
       "             ('successful',): Counter({'in': 1}),\n",
       "             ('applications.',): Counter({'</s>': 1}),\n",
       "             ('ethical',): Counter({'considerations': 1,\n",
       "                      'implications': 1,\n",
       "                      'and': 1}),\n",
       "             ('considerations',): Counter({'and': 1}),\n",
       "             ('responsible',): Counter({'ai': 1, 'use': 1}),\n",
       "             ('development',): Counter({'are': 1}),\n",
       "             ('are',): Counter({'becoming': 1, 'working': 1}),\n",
       "             ('becoming',): Counter({'increasingly': 1}),\n",
       "             ('increasingly',): Counter({'important': 1}),\n",
       "             ('important',): Counter({'as': 1}),\n",
       "             ('as',): Counter({'ai': 2}),\n",
       "             ('technologies',): Counter({'advance.': 1}),\n",
       "             ('advance.',): Counter({'</s>': 1}),\n",
       "             ('used',): Counter({'in': 1}),\n",
       "             ('diverse',): Counter({'applications,': 1}),\n",
       "             ('applications,',): Counter({'from': 1}),\n",
       "             ('from',): Counter({'virtual': 1, 'that': 1}),\n",
       "             ('virtual',): Counter({'assistants': 1}),\n",
       "             ('assistants',): Counter({'and': 1}),\n",
       "             ('recommendation',): Counter({'systems': 1}),\n",
       "             ('systems',): Counter({'to': 1}),\n",
       "             ('autonomous',): Counter({'vehicles': 1, 'decision-making.': 1}),\n",
       "             ('vehicles',): Counter({'and': 1}),\n",
       "             ('medical',): Counter({'diagnosis.': 1}),\n",
       "             ('diagnosis.',): Counter({'</s>': 1}),\n",
       "             ('turing',): Counter({'test,': 1}),\n",
       "             ('test,',): Counter({'proposed': 1}),\n",
       "             ('proposed',): Counter({'by': 1}),\n",
       "             ('by',): Counter({'alan': 1}),\n",
       "             ('alan',): Counter({'turing,': 1}),\n",
       "             ('turing,',): Counter({'is': 1}),\n",
       "             ('measure',): Counter({'of': 1}),\n",
       "             (\"machine's\",): Counter({'ability': 1}),\n",
       "             ('ability',): Counter({'to': 1}),\n",
       "             ('exhibit',): Counter({'intelligent': 1}),\n",
       "             ('intelligent',): Counter({'behavior': 1}),\n",
       "             ('behavior',): Counter({'indistinguishable': 1}),\n",
       "             ('indistinguishable',): Counter({'from': 1}),\n",
       "             ('human.',): Counter({'</s>': 1}),\n",
       "             ('potential',): Counter({'to': 1}),\n",
       "             ('revolutionize',): Counter({'industries,': 1}),\n",
       "             ('industries,',): Counter({'but': 1}),\n",
       "             ('but',): Counter({'it': 1}),\n",
       "             ('it',): Counter({'also': 1}),\n",
       "             ('also',): Counter({'raises': 1}),\n",
       "             ('raises',): Counter({'concerns': 1}),\n",
       "             ('concerns',): Counter({'about': 1}),\n",
       "             ('about',): Counter({'job': 1}),\n",
       "             ('job',): Counter({'displacement': 1}),\n",
       "             ('displacement',): Counter({'and': 1}),\n",
       "             ('implications',): Counter({'of': 1}),\n",
       "             ('decision-making.',): Counter({'</s>': 1}),\n",
       "             ('researchers',): Counter({'and': 1}),\n",
       "             ('policymakers',): Counter({'are': 1}),\n",
       "             ('working',): Counter({'on': 1}),\n",
       "             ('on',): Counter({'guidelines': 1, 'society.': 1}),\n",
       "             ('guidelines',): Counter({'and': 1}),\n",
       "             ('regulations',): Counter({'to': 1}),\n",
       "             ('ensure',): Counter({'the': 1}),\n",
       "             ('use',): Counter({'of': 1}),\n",
       "             ('technologies.',): Counter({'</s>': 1}),\n",
       "             ('continues',): Counter({'to': 1}),\n",
       "             ('evolve,',): Counter({'interdisciplinary': 1}),\n",
       "             ('interdisciplinary',): Counter({'collaboration': 1}),\n",
       "             ('collaboration',): Counter({'and': 1}),\n",
       "             ('public',): Counter({'awareness': 1}),\n",
       "             ('awareness',): Counter({'play': 1}),\n",
       "             ('play',): Counter({'crucial': 1}),\n",
       "             ('crucial',): Counter({'roles': 1}),\n",
       "             ('roles',): Counter({'in': 1}),\n",
       "             ('shaping',): Counter({'its': 1}),\n",
       "             ('its',): Counter({'impact': 1}),\n",
       "             ('impact',): Counter({'on': 1}),\n",
       "             ('society.',): Counter({'</s>': 1})})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_model = build_n_gram_model(preprocessed_corpus, 2)\n",
    "n_gram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a752bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_probabilities = calculate_n_gram_probabilities(n_gram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "644fb582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example N-Gram probabilities:\n",
      "('<s>',): {'artificial': 0.1, 'ai': 0.3, 'the': 0.2, 'deep': 0.1, 'ethical': 0.1, 'researchers': 0.1, 'as': 0.1}\n",
      "('artificial',): {'intelligence': 1.0}\n",
      "('intelligence',): {'(ai)': 0.5, 'in': 0.5}\n",
      "('(ai)',): {'is': 1.0}\n",
      "('is',): {'the': 0.25, 'designed': 0.25, 'used': 0.25, 'a': 0.25}\n"
     ]
    }
   ],
   "source": [
    "# Print example N-Gram probabilities (for brevity, print probabilities of the first few N-Grams)\n",
    "print(\"Example N-Gram probabilities:\")\n",
    "for n_gram, probabilities in list(n_gram_probabilities.items())[:5]:\n",
    "    print(f\"{n_gram}: {probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90a0ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_perplexity = calculate_perplexity(n_gram_probabilities, preprocessed_corpus, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5d53146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity of the N-Gram model: None\n"
     ]
    }
   ],
   "source": [
    "# Print the perplexity of the N-Gram model\n",
    "print(f\"\\nPerplexity of the N-Gram model: {n_gram_perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1e87d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N-gram neural network model (e.g., Trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0d0bb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/1e/86/477ec85bf1f122931f00a2f3889ed9322c091497415a563291ffc119dacc/torch-2.1.2-cp311-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torch-2.1.2-cp311-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in ./anaconda3/lib/python3.11/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in ./anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in ./anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./anaconda3/lib/python3.11/site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.1.2-cp311-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "Successfully installed torch-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7dc9d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the corpus\n",
    "corpus = [\n",
    "    \"Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics.\", \n",
    "    \"It is primarily concerned with giving computers the ability to support and manipulate human language.\", \n",
    "    \"It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic machine learning approaches.\", \n",
    "    \"The goal is a computer capable of understanding the contents of documents, including the contextual nuances of the language within them.\",\n",
    "    \"The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\",\n",
    "    \"Machine learning is a field of study in artificial intelligence concerned with the development of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.\",\n",
    "    \"Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.\",\n",
    "    \"Machine learning approaches have been applied to many fields including large language models, computer vision, and speech recognition.\",\n",
    "    \"Machine learning is known in its application across business problems under the name predictive analytics.\",\n",
    "    \"Although not all machine learning is statistically based, computational statistics is an important source of the field's methods.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc3952a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = '\\n'.join(corpus).split()\n",
    "vocab = set(corpus)\n",
    "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "idx_to_word = {word_to_idx[word]: word for word in word_to_idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "168a3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram = [((corpus[i], corpus[i + 1]), corpus[i + 2])\n",
    "           for i in range(len(corpus) - 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0bb85d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Natural', 'language'), 'processing'),\n",
       " (('language', 'processing'), '(NLP)'),\n",
       " (('processing', '(NLP)'), 'is'),\n",
       " (('(NLP)', 'is'), 'an'),\n",
       " (('is', 'an'), 'interdisciplinary'),\n",
       " (('an', 'interdisciplinary'), 'subfield'),\n",
       " (('interdisciplinary', 'subfield'), 'of'),\n",
       " (('subfield', 'of'), 'computer'),\n",
       " (('of', 'computer'), 'science'),\n",
       " (('computer', 'science'), 'and')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ae942a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NgramModel(nn.Module):\n",
    "    def __init__(self, vocb_size, context_size, n_dim):\n",
    "        super(NgramModel, self).__init__()\n",
    "        self.n_word = vocb_size\n",
    "        self.embedding = nn.Embedding(self.n_word, n_dim)\n",
    "        self.linear1 = nn.Linear(context_size * n_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, self.n_word)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        emb = emb.view(1, -1)\n",
    "        out = self.linear1(emb)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        log_prob = F.log_softmax(out)\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e203ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "ngrammodel = NgramModel(len(word_to_idx), CONTEXT_SIZE, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa1ce7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(ngrammodel.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94c21117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "**********\n",
      "Loss: 7.202061\n",
      "epoch: 2\n",
      "**********\n",
      "Loss: 7.117636\n",
      "epoch: 3\n",
      "**********\n",
      "Loss: 7.034456\n",
      "epoch: 4\n",
      "**********\n",
      "Loss: 6.952282\n",
      "epoch: 5\n",
      "**********\n",
      "Loss: 6.870747\n",
      "epoch: 6\n",
      "**********\n",
      "Loss: 6.789623\n",
      "epoch: 7\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67872/1619048659.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_prob = F.log_softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.708892\n",
      "epoch: 8\n",
      "**********\n",
      "Loss: 6.628068\n",
      "epoch: 9\n",
      "**********\n",
      "Loss: 6.546749\n",
      "epoch: 10\n",
      "**********\n",
      "Loss: 6.465104\n",
      "epoch: 11\n",
      "**********\n",
      "Loss: 6.382518\n",
      "epoch: 12\n",
      "**********\n",
      "Loss: 6.299143\n",
      "epoch: 13\n",
      "**********\n",
      "Loss: 6.214832\n",
      "epoch: 14\n",
      "**********\n",
      "Loss: 6.129460\n",
      "epoch: 15\n",
      "**********\n",
      "Loss: 6.042929\n",
      "epoch: 16\n",
      "**********\n",
      "Loss: 5.954959\n",
      "epoch: 17\n",
      "**********\n",
      "Loss: 5.865716\n",
      "epoch: 18\n",
      "**********\n",
      "Loss: 5.775320\n",
      "epoch: 19\n",
      "**********\n",
      "Loss: 5.683646\n",
      "epoch: 20\n",
      "**********\n",
      "Loss: 5.591035\n",
      "epoch: 21\n",
      "**********\n",
      "Loss: 5.497446\n",
      "epoch: 22\n",
      "**********\n",
      "Loss: 5.403441\n",
      "epoch: 23\n",
      "**********\n",
      "Loss: 5.309322\n",
      "epoch: 24\n",
      "**********\n",
      "Loss: 5.214977\n",
      "epoch: 25\n",
      "**********\n",
      "Loss: 5.120785\n",
      "epoch: 26\n",
      "**********\n",
      "Loss: 5.026653\n",
      "epoch: 27\n",
      "**********\n",
      "Loss: 4.932806\n",
      "epoch: 28\n",
      "**********\n",
      "Loss: 4.839269\n",
      "epoch: 29\n",
      "**********\n",
      "Loss: 4.745600\n",
      "epoch: 30\n",
      "**********\n",
      "Loss: 4.652169\n",
      "epoch: 31\n",
      "**********\n",
      "Loss: 4.558508\n",
      "epoch: 32\n",
      "**********\n",
      "Loss: 4.465082\n",
      "epoch: 33\n",
      "**********\n",
      "Loss: 4.371696\n",
      "epoch: 34\n",
      "**********\n",
      "Loss: 4.278191\n",
      "epoch: 35\n",
      "**********\n",
      "Loss: 4.184824\n",
      "epoch: 36\n",
      "**********\n",
      "Loss: 4.091452\n",
      "epoch: 37\n",
      "**********\n",
      "Loss: 3.998271\n",
      "epoch: 38\n",
      "**********\n",
      "Loss: 3.905167\n",
      "epoch: 39\n",
      "**********\n",
      "Loss: 3.812233\n",
      "epoch: 40\n",
      "**********\n",
      "Loss: 3.719730\n",
      "epoch: 41\n",
      "**********\n",
      "Loss: 3.627298\n",
      "epoch: 42\n",
      "**********\n",
      "Loss: 3.535399\n",
      "epoch: 43\n",
      "**********\n",
      "Loss: 3.443825\n",
      "epoch: 44\n",
      "**********\n",
      "Loss: 3.352718\n",
      "epoch: 45\n",
      "**********\n",
      "Loss: 3.262082\n",
      "epoch: 46\n",
      "**********\n",
      "Loss: 3.172044\n",
      "epoch: 47\n",
      "**********\n",
      "Loss: 3.082888\n",
      "epoch: 48\n",
      "**********\n",
      "Loss: 2.994152\n",
      "epoch: 49\n",
      "**********\n",
      "Loss: 2.906490\n",
      "epoch: 50\n",
      "**********\n",
      "Loss: 2.819397\n",
      "epoch: 51\n",
      "**********\n",
      "Loss: 2.733512\n",
      "epoch: 52\n",
      "**********\n",
      "Loss: 2.648513\n",
      "epoch: 53\n",
      "**********\n",
      "Loss: 2.564860\n",
      "epoch: 54\n",
      "**********\n",
      "Loss: 2.482257\n",
      "epoch: 55\n",
      "**********\n",
      "Loss: 2.400921\n",
      "epoch: 56\n",
      "**********\n",
      "Loss: 2.321051\n",
      "epoch: 57\n",
      "**********\n",
      "Loss: 2.242560\n",
      "epoch: 58\n",
      "**********\n",
      "Loss: 2.165705\n",
      "epoch: 59\n",
      "**********\n",
      "Loss: 2.090177\n",
      "epoch: 60\n",
      "**********\n",
      "Loss: 2.016574\n",
      "epoch: 61\n",
      "**********\n",
      "Loss: 1.944594\n",
      "epoch: 62\n",
      "**********\n",
      "Loss: 1.874347\n",
      "epoch: 63\n",
      "**********\n",
      "Loss: 1.805947\n",
      "epoch: 64\n",
      "**********\n",
      "Loss: 1.739399\n",
      "epoch: 65\n",
      "**********\n",
      "Loss: 1.674689\n",
      "epoch: 66\n",
      "**********\n",
      "Loss: 1.611889\n",
      "epoch: 67\n",
      "**********\n",
      "Loss: 1.551125\n",
      "epoch: 68\n",
      "**********\n",
      "Loss: 1.492191\n",
      "epoch: 69\n",
      "**********\n",
      "Loss: 1.435217\n",
      "epoch: 70\n",
      "**********\n",
      "Loss: 1.380416\n",
      "epoch: 71\n",
      "**********\n",
      "Loss: 1.327428\n",
      "epoch: 72\n",
      "**********\n",
      "Loss: 1.276581\n",
      "epoch: 73\n",
      "**********\n",
      "Loss: 1.227596\n",
      "epoch: 74\n",
      "**********\n",
      "Loss: 1.180668\n",
      "epoch: 75\n",
      "**********\n",
      "Loss: 1.135541\n",
      "epoch: 76\n",
      "**********\n",
      "Loss: 1.092541\n",
      "epoch: 77\n",
      "**********\n",
      "Loss: 1.051279\n",
      "epoch: 78\n",
      "**********\n",
      "Loss: 1.011886\n",
      "epoch: 79\n",
      "**********\n",
      "Loss: 0.974300\n",
      "epoch: 80\n",
      "**********\n",
      "Loss: 0.938525\n",
      "epoch: 81\n",
      "**********\n",
      "Loss: 0.904417\n",
      "epoch: 82\n",
      "**********\n",
      "Loss: 0.871876\n",
      "epoch: 83\n",
      "**********\n",
      "Loss: 0.841116\n",
      "epoch: 84\n",
      "**********\n",
      "Loss: 0.811742\n",
      "epoch: 85\n",
      "**********\n",
      "Loss: 0.783855\n",
      "epoch: 86\n",
      "**********\n",
      "Loss: 0.757487\n",
      "epoch: 87\n",
      "**********\n",
      "Loss: 0.732422\n",
      "epoch: 88\n",
      "**********\n",
      "Loss: 0.708573\n",
      "epoch: 89\n",
      "**********\n",
      "Loss: 0.686026\n",
      "epoch: 90\n",
      "**********\n",
      "Loss: 0.664587\n",
      "epoch: 91\n",
      "**********\n",
      "Loss: 0.644413\n",
      "epoch: 92\n",
      "**********\n",
      "Loss: 0.625197\n",
      "epoch: 93\n",
      "**********\n",
      "Loss: 0.607030\n",
      "epoch: 94\n",
      "**********\n",
      "Loss: 0.589801\n",
      "epoch: 95\n",
      "**********\n",
      "Loss: 0.573486\n",
      "epoch: 96\n",
      "**********\n",
      "Loss: 0.558069\n",
      "epoch: 97\n",
      "**********\n",
      "Loss: 0.543303\n",
      "epoch: 98\n",
      "**********\n",
      "Loss: 0.529471\n",
      "epoch: 99\n",
      "**********\n",
      "Loss: 0.516324\n",
      "epoch: 100\n",
      "**********\n",
      "Loss: 0.503737\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    print('epoch: {}'.format(epoch + 1))\n",
    "    print('*' * 10)\n",
    "    running_loss = 0\n",
    "    for data in trigram:\n",
    "        word, label = data     #E.g., word = ('Natural', 'language'); label = 'processing'\n",
    "        word = Variable(torch.LongTensor([word_to_idx[i] for i in word]))\n",
    "        label = Variable(torch.LongTensor([word_to_idx[label]]))\n",
    "        \n",
    "        # forward -- for prediction and calculating the loss for each instance\n",
    "        out = ngrammodel(word)\n",
    "        loss = criterion(out, label)    \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # backward -- for gradiate update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # print the average loss\n",
    "    print('Loss: {:.6f}'.format(running_loss / len(word_to_idx)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88e1ab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('(NLP)', 'is') \t an\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word, label = trigram[3]\n",
    "print(word, '\\t', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e2e8cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 \t 36\n"
     ]
    }
   ],
   "source": [
    "print(word_to_idx['(NLP)'], '\\t', word_to_idx['is'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b97e6409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67872/1619048659.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_prob = F.log_softmax(out)\n"
     ]
    }
   ],
   "source": [
    "word = Variable(torch.LongTensor([word_to_idx[i] for i in word]))\n",
    "out = ngrammodel(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55fa38a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.8025,  -6.6306,  -7.6776,  -8.4790,  -7.2053,  -8.0369,  -9.3851,\n",
       "          -8.2271,  -8.9402,  -9.0661,  -6.9189,  -7.8263,  -7.3986,  -8.1753,\n",
       "          -9.2513,  -8.3883,  -8.8400,  -6.8880,  -5.9797,  -7.0213,  -8.0637,\n",
       "          -8.3375,  -8.4219,  -8.0314,  -7.8549,  -8.5214,  -7.7298,  -7.9354,\n",
       "          -9.2482,  -7.1365,  -6.7070,  -6.7819,  -6.8558,  -8.9761,  -6.3744,\n",
       "          -7.6374,  -7.3776,  -8.7189,  -7.6748,  -8.2060,  -8.7828,  -6.5718,\n",
       "          -7.8516,  -5.5209,  -8.9169,  -7.6570,  -7.1296,  -7.9354,  -7.4967,\n",
       "          -7.3807,  -8.7286,  -4.4824,  -7.3743,  -8.1332,  -8.0992,  -4.3666,\n",
       "          -7.5409,  -8.7871,  -7.7525,  -8.5492,  -6.0472,  -4.5289,  -7.3960,\n",
       "         -10.1769,  -6.0644,  -4.7673,  -8.6896,  -7.5080,  -8.9787,  -7.2784,\n",
       "          -0.1526,  -8.1846,  -6.6605,  -8.1420,  -8.1736,  -7.8749,  -8.4260,\n",
       "          -9.1426,  -7.9542,  -8.2479,  -8.7789,  -8.4692,  -7.8952,  -8.1765,\n",
       "          -6.1787,  -7.9131,  -7.5189,  -8.3561,  -7.4472,  -8.3244,  -7.2925,\n",
       "          -8.4552,  -9.1666,  -9.3024,  -9.0474,  -8.6299,  -7.3554,  -5.9873,\n",
       "          -8.7921,  -8.9143,  -7.5763,  -7.8260,  -8.0724,  -8.7504,  -8.2666,\n",
       "          -7.1632,  -8.7545,  -8.2927,  -8.4946,  -7.0972,  -8.5439,  -8.1527,\n",
       "          -7.5870,  -9.7656,  -7.1878,  -8.3881,  -6.9892,  -5.7775,  -3.5080,\n",
       "          -7.5915,  -7.7602,  -8.7027,  -7.3833,  -7.5001,  -7.3180,  -8.3411,\n",
       "          -9.9267,  -7.5813,  -8.3276]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92f829b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predict_label = torch.max(out, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4afaa44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([70])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b187318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real word is: an,\n",
      "predict word is: an\n"
     ]
    }
   ],
   "source": [
    "predict_word = idx_to_word[predict_label.item()]\n",
    "print('real word is: {},\\npredict word is: {}'.format(label, predict_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a754337a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
